# ubuntu 上快速用 WasmEdge 运行 LLM

WasmEdge作为一种高性能的WebAssembly运行时，能够在多种环境中高效运行WASM应用。本文将详细介绍如何在Ubuntu系统上使用WasmEdge来运行WASM推理应用程序，并加载GGUF模型（如LLaMA-2-7B），以便进行实时聊天交互。



## 安装 WasmEdge

### 步骤1：安装依赖

首先，打开Ubuntu的终端并更新软件包列表：

```bash
sudo apt update
```

接着，安装必要的依赖：

```bash
sudo apt install -y curl wget git build-essential
```



### 步骤2：安装 WasmEdge

可以通过以下命令安装WasmEdge：

```bash
$ curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install.sh | bash
Using Python: /home/openim/miniconda3/bin/python3 
ERROR   - Exception on process - rc= 127 output= b'' command= ['/usr/local/cuda/bin/nvcc --version 2>/dev/null']
INFO    - Compatible with current configuration
INFO    - Running Uninstaller
WARNING - SHELL variable not found. Using bash as SHELL
INFO    - shell configuration updated
INFO    - Downloading WasmEdge
|============================================================|100.00 %INFO    - Downloaded
INFO    - Installing WasmEdge
INFO    - WasmEdge Successfully installed
INFO    - Run:
source /home/openim/.bashrc
```

> WasmEdge 默认被安装在 `$HOME/.wasmedge` 目录中。你也可以将其安装到系统目录，如 `/usr/local`，以使其对所有用户可用。若要指定安装目录，应使用 `install.sh -p` 进行安装，由于这些命令会执行会写入系统目录的操作，所以需要以 `root` 用户或使用 `sudo` 执行：
>
> ```
> curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install.sh | bash -s -- -p /usr/local
> ```



### 步骤3：验证安装

完成安装后，验证WasmEdge是否正确安装：

```bash
$ wasmedge --version
wasmedge version 0.13.5
```



## 运行 LLM

### 步骤1：获取 LLM WASM 包

您需要先获取或构建一个LLM的WASM包。假设您已有一个可用的WASM包，例如`llm.wasm`。

**下载预构建的 Wasm 应用和模型**

```bash
$ curl -LO https://github.com/second-state/llama-utils/raw/main/chat/llama-chat.wasm
```

你还应该下载一个 GGUF 格式的 llama2 模型。下面的例子下载了一个调整为5位权重的 llama2 7B聊天模型。

```bash
$ curl -LO https://huggingface.co/wasmedge/llama2/resolve/main/llama-2-7b-chat-q5_k_m.gguf
```

**运行**

> 使用 WasmEdge 运行 wasm 推理应用程序，同时加载 GGUF 模型。现在，你可以输入问题与模型进行聊天了。

```bash
wasmedge --dir .:. --nn-preload default:GGML:AUTO:llama-2-7b-chat-q5_k_m.gguf llama-chat.wasm
```

这条命令做了以下几件事情：

- `--dir .:.` 允许应用访问当前目录。
- `--nn-preload default:GGML:AUTO:llama-2-7b-chat-q5_k_m.gguf` 加载GGUF模型。



### 步骤2：运行 LLM

使用WasmEdge运行LLM：







