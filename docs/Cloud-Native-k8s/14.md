+ [author](http://nsddd.top)

# 第14节 k3s

<div><a href = '13.md' style='float:left'>⬆️上一节🔗  </a><a href = '15.md' style='float: right'>  ⬇️下一节🔗</a></div>
<br>

> ❤️💕💕新时代拥抱云原生，云原生具有环境统一、按需付费、即开即用、稳定性强特点。Myblog:[http://nsddd.top](http://nsddd.top/)

---
[[toc]]

[toc]

## k3s介绍

::: tip k3s — 微型kubernets发行版
k3s是经CNCF一致性认证的Kubernetes发行版，专为物联网及边缘计算设计。

+ [官方](https://www.rancher.cn/k3s/)
+ [文档](https://docs.rancher.cn/)
+ [开源地址](https://github.com/k3s-io/k3s/)

**技术亮点：**

+ 单进程架构简化部署
+ 移除各种非必要的代码，减少资源占用
+ `TLS` 证书管理
+ 内置 `Containerd`
+ 内置自运行 `rootfs`
+ 内置 `Helm Chart` 管理机制
+ 内置 `L4/L7 LB` 支持



**适合场景：**

+ 边缘计算-Edge
+ 物联网-IoT
+ CI
+ Development
+ ARM
+ 嵌入 K8s

:::



## k3s和k8s区别

::: tip 
K3s是一个独立的服务器，与K8s不同，它是Kubernetes集群的一部分。K8s依靠CRI-O来整合Kubernetes与CRI（容器运行时接口），而K3s使用CRI-O与所有支持的容器运行时兼容。K8s使用kubelet来调度容器，但K3s使用主机的调度机制来调度容器。

:::

k3s有比k8s更严格的安全部署，因为其攻击面小。k3s的另一个优势是，它可以减少安装、运行或更新Kubernetes集群所需的依赖性和步骤。





## 架构

k3s架构就是把k8s核心组件封装成二进制~

k3s分为`k3s server` 和 ` k3s agent`：

+  k3s server 只有一个进程体
+  k3s agent 分为两个进程体，其中一个是 Contrainerd，负责管理运行容器

> 在下面也可以深刻理解到



**架构详解：**

::: details 架构讲解：
k3s算是对k8s的架构和生态进行一部分精华和缩进

**单节点架构：**

K3s 单节点集群的架构如下图所示，该集群有一个内嵌 SQLite 数据库的单节点  `K3s server` 。

在这种配置中，每个  `agent` 节点都注册到同一个  `server` 节点。K3s 用户可以通过调用  `server` 节点上的 K3s API 来操作 Kubernetes 资源。

单节点 `K3s server` 的架构

![img](http://sm.nsddd.top/sm1660616402558126.png)

**高可用架构：**

虽然单节点 k3s 集群可以满足各种用例，但对于 Kubernetes control-plane 的正常运行至关重要的环境，您可以在高可用配置中运行 K3s。一个高可用 K3s 集群由以下几个部分组成：

+ **`K3s server` 节点** ：两个或更多的`server`节点将为 Kubernetes API 提供服务并运行其他 control-plane 服务
+ **外部数据库** ：与单节点 k3s 设置中使用的嵌入式 `SQLite` 数据存储相反，高可用 K3s 需要挂载一个 `external database` 外部数据库作为数据存储的媒介。

**K3s高可用架构：**

![img](http://sm.nsddd.top/sm1660616476551520.png)

> 注意：高可用结构同样可以使用**嵌入式数据库**
>
> ⚠️ 区别：
>
> **嵌入数据库是指数据在内存中数据库，英文称为–embedded**，又称in-memory embedded database，如H2, HSQL and Derby databases。
>
> **非嵌入式数据库是指数据在磁盘中的数据库**，如MariaDB, MySQL and Oracle。

![image-20221117173105788](http://sm.nsddd.top/smimage-20221117173105788.png)

**固定  `agent` 节点的注册地址：**

在高可用   `K3s server`  配置中，每个节点还必须使用固定的注册地址向 Kubernetes API 注册，注册后， `agent` 节点直接与其中一个  `server` 节点建立连接，如下图所示：

![k3s-production-setup](http://sm.nsddd.top/sm1660616545857393.svg)

**注册  `agent` 节点：**

 `agent` 节点用`k3s agent`进程发起的 websocket 连接注册，连接由作为代理进程一部分运行的客户端负载均衡器维护。

 `agent` 将使用节点集群 secret 以及随机生成的节点密码向   `K3s server`  注册，密码存储在 `/etc/rancher/node/password`路径下。 `K3s server` 将把各个节点的密码存储为 Kubernetes secrets，随后的任何尝试都必须使用相同的密码。节点密码秘密存储在`kube-system`命名空间中，名称使用模板`<host>.node-password.k3s`。

> **注意：**
>
> + 在 K3s v1.20.2 之前，` K3s  server` 将密码存储在`/var/lib/rancher/k3s/server/cred/node-passwd`的磁盘上。
> + 如果您删除了  `agent` 的`/etc/rancher/node`目录，则需要为该  `agent` 重新创建密码文件，或者从  `server` 中删除该条目。
> + 通过使用`--with-node-id`标志启动 `  K3s server` 或 agent，可以将唯一的节点 ID 附加到主机名中。

**自动部署的清单：**

位于目录路径`/var/lib/rancher/k3s/server/manifests` 的清单在构建时被捆绑到 K3s 二进制文件中，将由[rancher/helm-controller](https://github.com/k3s-io/helm-controller#helm-controller)在运行时安装。

:::



## Sqlite 和 Dqlite

我认为我在这里遇到了很多疑惑，关于 Sqlite 和 [Dqlite](https://github.com/canonical/dqlite/blob/master/README_CH.md)

::: tip dqlite
“dqlite”是“distributed SQLite”的简写，即分布式SQLite。意味着 dqlite 通过网络协议扩展 SQLite ，将应用程序的各个实例连接在一起，让它们作为一个高可用的集群，而不依赖外部数据库。
:::

我希望 runtime 可以实现 multi-master ，同样支持的嵌入式和外部DB



::: danger 
关于 单结点 扩展为 高可用 状态，或许这并不是一个很容器实现的地方，我们在前面 details 中看到单结点架构和高可用架构的区别，或许我们应该在制作 `runtime` 模块 和 `rootfs` 的时候更倾向于实现 高可用。
:::



**架构图：**

![k3s下载](http://sm.nsddd.top/smhow-it-works-k3s.svg)



## 目录结构

+ 位于目录路径 /var/lib/`/var/lib/rancher/k3s/server/manifests` 的[清单](https://github.com/rancher/k3s/tree/master/manifests)在构建时捆绑到 K3s 二进制文件中。这些将由[rancher/helm-controller.](https://github.com/rancher/helm-controller#helm-controller)在运行的时候自动安装

```bash
root@ubuntu:/var/lib/rancher/k3s/server# cd manifests/;ls;pwd
ccm.yaml      local-storage.yaml  rolebindings.yaml
coredns.yaml  metrics-server      traefik.yaml
/var/lib/rancher/k3s/server/manifests
```

+ 可以将主要的 k3s 二进制文件放在任何您想要的地方。它会将内容写入 /var/lib/rancher/k3s 和 /etc/rancher，以及 containerd 和 kubelet 用于非持久文件的正常位置 /var/run 下。



## 新版本默认支持 etcd

::: tip
从 `v1.19.5+k3s1` 版本开始，K3s 已添加了对嵌入式 etcd 的完全支持。从 v1.19.1 到 v1.19.4 版本只提供了对嵌入式 etcd 的实验性支持。在 K3s v1.19.1 版本中，嵌入式 etcd 取代了实验性的 Dqlite。这是一个突破性的变化。请注意，不支持从实验性 Dqlite 升级到嵌入式 etcd。如果你尝试升级，升级将不会成功，并且数据将会丢失。

嵌入式 etcd (HA) 在速度较慢的磁盘上可能会出现性能问题，例如使用 SD 卡运行的 Raspberry Pi。

⚠️ 注意，如果你使用 docker 作为runtime，请小心 docker 是不认识 `+` ，如果你希望的到指定版本，请使用 ： `v1.19.5-k3s1` 

:::



## 安装（卸载）k3s

::: warning 启动k3s有多快？
一行代码搞定 — 仅需30秒，即可启动k3s：

```bash
curl -sfL https://get.k3s.io | sh -
# Check for Ready node, takes maybe 30 seconds
k3s kubectl get node

# if u in china, u can speed up the installation in the following ways
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -
# -s 不输出任何东西  &  -f 连接失败时不显示http错误  & -L参数会让 HTTP 请求跟随服务器的重定向。curl 默认不跟随重定向。
```

> **同样你可以选择把k3s部署在docker中，这样你就可以很方便的管理k3s**
>
> `curl -sfL https://get.k3s.io | sh -` 将其 `server` 和 `agent` 都安装上了。
>
> **如何扩充结点**

**安装选项：**

+ [使用脚本安装的选项](https://docs.rancher.cn/docs/k3s/installation/install-options/_index#使用脚本安装的选项)
+ [从二进制中安装的选项](https://docs.rancher.cn/docs/k3s/installation/install-options/_index#从二进制安装的选项)
+ [K3s server 的注册选项](https://docs.rancher.cn/docs/k3s/installation/install-options/_index#k3s-server-的注册选项)
+ [K3s agent 的注册选项](https://docs.rancher.cn/docs/k3s/installation/install-options/_index#k3s-agent-的注册选项)
+ [配置文件](https://docs.rancher.cn/docs/k3s/installation/install-options/_index#配置文件)



**离线安装：**

+ [https://docs.rancher.cn/docs/k3s/installation/airgap/_index/](https://docs.rancher.cn/docs/k3s/installation/airgap/_index/)



日志查看k3s启动信息：

```bash
tail -f /var/log/syslog
# 或者
kubectl get all -n kube-system
```

:::



## 在线安装的解析

### 指定版本

**我们前面默认安装最新版，或许我们可以指定版本安装：**

```bash
curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.25.3 sh -
```



### 指定数据库

::: tip 场景
![image-20221124193104746](http://sm.nsddd.top/smimage-20221124193104746.png)

:::

**以MySQL为例：**

```bash
curl -sfL https://get.k3s.io | sh -s - server --datastore-endpoint='mysql://admin:Rancher2019k3s@tcp(k3s-mysql.csrskwupj33i.ca-central-1.rds.amazonaws.com:3306)/k3sdb'
# 注意database name不要加特殊字符
```

**任意节点查看node：**

```bash
kubectl get no
```



### 指定容器运行时

**运行时：**

```bash
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="--docker" sh -

# Domestic mirror acceleration
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn | INSTALL_K3S_EXEC="--docker"  sh -
```

> 这样我们可以使用 docker 来管理 k3s 

| Flag                                 | 默认值                             | 描述                                               |
| ------------------------------------ | ---------------------------------- | -------------------------------------------------- |
| `--docker`                           | N/A                                | 用 docker 代替 containerd                          |
| `--container-runtime-endpoint` value | N/A                                | 禁用嵌入式 containerd，使用替代的 CRI 实现。       |
| `--pause-image` value                | "docker.io/rancher/pause:3.1"      | 针对 containerd 或 Docker 的自定义 pause 镜像      |
| `--snapshotter` value                | N/A                                | 覆盖默认的 containerd 快照程序 (默认: "overlayfs") |
| `--private-registry` value           | "/etc/rancher/k3s/registries.yaml" | 私有镜像仓库配置文件                               |



::: details k3s安装动态

```bash
root@ubuntu:/sealos# curl -fL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 29713  100 29713    0     0   148k      0 --:--:-- --:--:-- --:--:--  149k
[INFO]  Finding release for channel stable
[INFO]  Using v1.25.3+k3s1 as release
[INFO]  Downloading hash rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/v1.25.3-k3s1/sha256sum-amd64.txt
[INFO]  Downloading binary rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/v1.25.3-k3s1/k3s
[INFO]  Verifying binary download
[INFO]  Installing k3s to /usr/local/bin/k3s
[INFO]  Skipping installation of SELinux RPM
[INFO]  Creating /usr/local/bin/kubectl symlink to k3s
[INFO]  Creating /usr/local/bin/crictl symlink to k3s
[INFO]  Skipping /usr/local/bin/ctr symlink to k3s, command exists in PATH at /usr/bin/ctr
[INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
[INFO]  Creating uninstall script /usr/local/bin/k3s-uninstall.sh
[INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env
[INFO]  systemd: Creating service file /etc/systemd/system/k3s.service
[INFO]  systemd: Enabling k3s unit
Created symlink /etc/systemd/system/multi-user.target.wants/k3s.service → /etc/systemd/system/k3s.service.
[INFO]  systemd: Starting k3s
################################################################################
root@ubuntu:/sealos# k3s
NAME:
   k3s - Kubernetes, but small and simple

USAGE:
   k3s [global options] command [command options] [arguments...]

VERSION:
   v1.25.3+k3s1 (f2585c16)

COMMANDS:
   server           Run management server
   agent            Run node agent
   kubectl          Run kubectl
   crictl           Run crictl
   ctr              Run ctr
   check-config     Run config check
   etcd-snapshot    Trigger an immediate etcd snapshot
   secrets-encrypt  Control secrets encryption and keys rotation
   certificate      Certificates management
   completion       Install shell completion script
   help, h          Shows a list of commands or help for one command

GLOBAL OPTIONS:
   --debug                     (logging) Turn on debug logs [$K3S_DEBUG]
   --data-dir value, -d value  (data) Folder to hold state (default: /var/lib/rancher/k3s or ${HOME}/.rancher/k3s if not root)
   --help, -h                  show help
   --version, -v               print the version

```

:::



## 离线安装解释

::: tip 提醒
下载离线安装脚本：https://get.k3s.io

下载**k3s**二进制文件：k3s

下载必要的`images`：

```bash
wget https://ghproxy.com/https://github.com/k3s-io/k3s/releases/download/v1.25.3%2Bk3s1/k3s-airgap-images-amd64.tar
```

> **These files are available in the [GitHub](https://github.com/k3s-io/k3s/) repository**
>
> ![image-20221109164523589](http://sm.nsddd.top/smimage-20221109164523589.png)

:::



### 步骤

**步骤 1**：部署镜像，本文提供了两种部署方式，分别是**部署私有镜像仓库**和**手动部署镜像**。请在这两种方式中选择一种执行。

**步骤 2**：安装 K3s，本文提供了两种安装方式，分别是**单节点安装**和**高可用安装**。完成镜像部署后，请在这两种方式中选择一种执行。

**离线升级 K3s 版本**：完成离线安装 K3s 后，您还可以通过脚本升级 K3s 版本，或启用自动升级功能，以保持离线环境中的 K3s 版本与最新的 K3s 版本同步。



**请按照以下步骤准备镜像目录和 K3s 二进制文件：**

> 我认为离线安装的重点在于**K3s 依赖的镜像**部分，因为 K3s 的"安装脚本"和"二进制文件"只需要下载到对应目录，然后赋予相应的权限即可，非常简单。但K3s 依赖的镜像的安装方式取决于你使用的是手动部署镜像还是私有镜像仓库，也取决于容器运行时使用的是 `containerd` 还是`docker`。
>
> 针对不同的组合形式，可以分为以下几种形式来实现离线安装：
>
> + Containerd + 手动部署镜像方式
> + Docker + 手动部署镜像方式
> + Containerd + 私有镜像仓库方式
> + Docker + 私有镜像仓库方式

1. 从[K3s GitHub Release](https://github.com/rancher/k3s/releases)页面获取你所运行的 K3s 版本的镜像 tar 文件。(**airgap-images**)

2. 将 tar 文件放在`images`目录下，例如：

   ```bash
   sudo mkdir -p /var/lib/rancher/k3s/agent/images/
   sudo cp ./k3s-airgap-images-$ARCH.tar /var/lib/rancher/k3s/agent/images/
   ```


3. 将 k3s 二进制文件放在 `/usr/local/bin/k3s`路径下，并确保拥有可执行权限。完成后，现在可以转到下面的[安装 K3s](https://docs.rancher.cn/docs/k3s/installation/airgap/_index#安装-k3s)部分，开始安装 K3s。



### 前提条件

+ 在安装 K3s 之前，完成上面的[部署私有镜像仓库](https://docs.rancher.cn/docs/k3s/installation/airgap/_index#部署私有镜像仓库)或[手动部署镜像](https://docs.rancher.cn/docs/k3s/installation/airgap/_index#手动部署镜像)，导入安装 K3s 所需要的镜像。
+ 从 [release](https://github.com/rancher/k3s/releases) 页面下载 K3s 二进制文件，K3s 二进制文件需要与离线镜像的版本匹配。将二进制文件放在每个离线节点的 `/usr/local/bin` 中，并确保这个二进制文件是可执行的。
+ 下载 K3s 安装脚本：[https://get.k3s.io](https://get.k3s.io/) 。将安装脚本放在每个离线节点的任意地方，并命名为 `install.sh`。

当使用 `INSTALL_K3S_SKIP_DOWNLOAD` 环境变量运行 K3s 脚本时，K3s 将使用本地的脚本和二进制。



::: warning 提醒 u
您可以在离线环境中执行单节点安装，在一个 server（节点）上安装 K3s，或高可用安装，在多个 server（节点）上安装 K3s。

对安装脚本进行简单的修改（ghproxy），在最后可以看到 安装脚本~

:::



### Containerd + 手动部署镜像方式

::: details 展开查看步骤
假设你已经将同一版本的 K3s 的安装脚本(`k3s-install.sh`)、K3s 的二进制文件(`k3s`)、K3s 依赖的镜像(`k3s-airgap-images-amd64.tar`)下载到了`/root`目录下。

如果你使用的容器运行时为containerd，在启动 K3s 时，它会检查`/var/lib/rancher/k3s/agent/images/`是否存在可用的镜像压缩包，如果存在，就将该镜像导入到 `containerd` 镜像列表中。所以我们只需要下载 `K3s` 依赖的镜像到`/var/lib/rancher/k3s/agent/images/`目录，然后启动 `K3s` 即可。



**1. 导入镜像到 `containerd` 的镜像列表：**

```bash
sudo mkdir -p /var/lib/rancher/k3s/agent/images/
sudo cp /root/k3s-airgap-images-amd64.tar /var/lib/rancher/k3s/agent/images/
```



**2. 将 K3s 安装脚本和 K3s 二进制文件移动到对应目录并授予可执行权限**

```bash
sudo chmod a+x /root/k3s /root/k3s-install.sh
sudo cp /root/k3s /usr/local/bin/
```



**3. 安装 K3s**

```bash
INSTALL_K3S_SKIP_DOWNLOAD=true /root/k3s-install.sh
```

:::



::: details 演示

```bash
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# cp k3s-install.sh /root/k3s-install.sh
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# ls 
images  k3s  k3s-install.sh  Kubefile  sealer-runtime-demo
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# cp k3s  /root/k3s
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# sudo chmod a+x /root/k3s /root/k3s-install.sh
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# sudo cp /root/k3s /usr/local/bin/
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# INSTALL_K3S_SKIP_DOWNLOAD=true /root/k3s-install.sh
[INFO]  Skipping k3s download and verify
[INFO]  Skipping installation of SELinux RPM
[INFO]  Skipping /usr/local/bin/kubectl symlink to k3s, command exists in PATH at /usr/bin/kubectl
[INFO]  Skipping /usr/local/bin/crictl symlink to k3s, command exists in PATH at /usr/bin/crictl
[INFO]  Skipping /usr/local/bin/ctr symlink to k3s, command exists in PATH at /usr/bin/ctr
[INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
[INFO]  Creating uninstall script /usr/local/bin/k3s-uninstall.sh
[INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env
[INFO]  systemd: Creating service file /etc/systemd/system/k3s.service
[INFO]  systemd: Enabling k3s unit
Created symlink from /etc/systemd/system/multi-user.target.wants/k3s.service to /etc/systemd/system/k3s.service.
[INFO]  systemd: Starting k3s
Failed to restart k3s.service: Unit is not loaded properly: Invalid argument.
See system logs and 'systemctl status k3s.service' for details.
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# k3s
NAME:
   k3s - Kubernetes, but small and simple

USAGE:
   k3s [global options] command [command options] [arguments...]

VERSION:
   v1.25.3+k3s1 (f2585c16)

COMMANDS:
   server           Run management server
   agent            Run node agent
   kubectl          Run kubectl
   crictl           Run crictl
   ctr              Run ctr
   check-config     Run config check
   etcd-snapshot    Trigger an immediate etcd snapshot
   secrets-encrypt  Control secrets encryption and keys rotation
   certificate      Certificates management
   completion       Install shell completion script
   help, h          Shows a list of commands or help for one command

GLOBAL OPTIONS:
   --debug                     (logging) Turn on debug logs [$K3S_DEBUG]
   --data-dir value, -d value  (data) Folder to hold state (default: /var/lib/rancher/k3s or ${HOME}/.rancher/k3s if not root)
   --help, -h                  show help
   --version, -v               print the version

```

**验证：**

```bash
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# crictl images
WARN[0000] image connect using default endpoints: [unix:///var/run/dockershim.sock unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock]. As the default settings are now deprecated, you should set the endpoint instead. 
IMAGE                                    TAG                 IMAGE ID            SIZE
k0sproject/k0s                           latest              6adc65a599f7a       253MB
nginx                                    latest              76c69feac34e8       142MB
registry                                 2.7.1               0d0107588605f       25.7MB
sea.hub:5000/calico/apiserver            v3.22.1             b7dd079a4ed76       129MB
sea.hub:5000/calico/cni                  v3.22.1             2a8ef6985a3e5       236MB
sea.hub:5000/calico/kube-controllers     v3.22.1             c0c6672a66a59       132MB
sea.hub:5000/calico/node                 v3.22.1             7a71aca7b60fc       198MB
sea.hub:5000/calico/pod2daemon-flexvol   v3.22.1             17300d20daf93       19.7MB
sea.hub:5000/calico/typha                v3.22.1             f822f80398b9a       127MB
sea.hub:5000/coredns                     1.7.0               bfe3a36ebd252       45.2MB
sea.hub:5000/etcd                        3.4.13-0            0369cf4303ffd       253MB
sea.hub:5000/kube-apiserver              v1.19.8             9ba91a90b7d1b       119MB
sea.hub:5000/kube-controller-manager     v1.19.8             213ae7795128d       111MB
sea.hub:5000/kube-proxy                  v1.19.8             ea03182b84a23       118MB
sea.hub:5000/kube-scheduler              v1.19.8             919a3f36437dc       46.5MB
sea.hub:5000/pause                       3.2                 80d28bedfe5de       683kB
sea.hub:5000/tigera/operator             v1.25.3             648350e58702c       128MB
[root@iZbp1evo5cnwagauz3w188Z k3s-offline]# kubectl get pods -A
NAMESPACE          NAME                                              READY   STATUS    RESTARTS   AGE
calico-apiserver   calico-apiserver-64f668766b-dv2xk                 1/1     Running   2          4d17h
calico-apiserver   calico-apiserver-64f668766b-k49gx                 1/1     Running   2          4d17h
calico-system      calico-kube-controllers-69dfd59986-mq7cv          1/1     Running   0          4d17h
calico-system      calico-node-pg47k                                 1/1     Running   0          4d17h
calico-system      calico-typha-84f56b949f-t95jk                     1/1     Running   0          4d17h
default            myapp                                             0/3     Pending   0          4d14h
kube-system        coredns-55bcc669d7-74xb2                          1/1     Running   0          4d17h
kube-system        coredns-55bcc669d7-jdkj2                          1/1     Running   0          4d17h
kube-system        etcd-izbp1evo5cnwagauz3w188z                      1/1     Running   0          4d17h
kube-system        kube-apiserver-izbp1evo5cnwagauz3w188z            1/1     Running   0          4d17h
kube-system        kube-controller-manager-izbp1evo5cnwagauz3w188z   1/1     Running   0          4d17h
kube-system        kube-proxy-ssr6t                                  1/1     Running   0          4d17h
kube-system        kube-scheduler-izbp1evo5cnwagauz3w188z            1/1     Running   0          4d17h
tigera-operator    tigera-operator-7cdb76dd8b-ltbbs                  1/1     Running   10         4d17h
```

:::





### Docker + 手动部署镜像方式

::: details 展开查看步骤
假设你已经将同一版本的 K3s 的安装脚本(`k3s-install.sh`)、K3s 的二进制文件(`k3s`)、K3s 依赖的镜像(`k3s-airgap-images-amd64.tar`)下载到了`/root`目录下。

与 `containerd` 不同，使用 docker 作为容器运行时，启动 `K3s` 不会导入 `/var/lib/rancher/k3s/agent/images/`目录下的镜像。所以在启动 `K3s` 之前我们需要将 `K3s` 依赖的镜像手动导入到 `docker` 镜像列表中。



**1. 导入镜像到 `docker` 的镜像列表：**

```bash
sudo docker load -i /root/k3s-airgap-images-amd64.tar
```



**2. 将 K3s 安装脚本和 K3s 二进制文件移动到对应目录并授予可执行权限**

```bash
sudo chmod a+x /root/k3s /root/k3s-install.sh
sudo cp /root/k3s /usr/local/bin/
```



**3. 安装 K3s**

```bash
INSTALL_K3S_SKIP_DOWNLOAD=true INSTALL_K3S_EXEC='--docker' /root/k3s-install.sh
```

:::





### Containerd + 手动部署镜像方式

::: details 展开查看步骤
假设你已经将同一版本的 K3s 的安装脚本(`k3s-install.sh`)、K3s 的二进制文件(`k3s`)、K3s 依赖的镜像(`k3s-airgap-images-amd64.tar`)下载到了`/root`目录下。

如果你使用的容器运行时为containerd，在启动 K3s 时，它会检查`/var/lib/rancher/k3s/agent/images/`是否存在可用的镜像压缩包，如果存在，就将该镜像导入到 `containerd` 镜像列表中。所以我们只需要下载 `K3s` 依赖的镜像到`/var/lib/rancher/k3s/agent/images/`目录，然后启动 `K3s` 即可。



**1. 导入镜像到 `containerd` 的镜像列表：**

```bash
sudo mkdir -p /var/lib/rancher/k3s/agent/images/
sudo cp /root/k3s-airgap-images-amd64.tar /var/lib/rancher/k3s/agent/images/
```



**2. 将 K3s 安装脚本和 K3s 二进制文件移动到对应目录并授予可执行权限**

```bash
sudo chmod a+x /root/k3s /root/k3s-install.sh
sudo cp /root/k3s /usr/local/bin/
```



**3. 安装 K3s**

```bash
INSTALL_K3S_SKIP_DOWNLOAD=true /root/k3s-install.sh
```

:::



### Containerd + 私有镜像仓库方式

::: details 展开查看详细
假设你已经将同一版本的 K3s 的安装脚本(`k3s-install.sh`)、K3s 的二进制文件(k3s)下载到了`/root`目录下。并且 `K3s` 所需要的镜像已经上传到了镜像仓库（本例的镜像仓库地址为：http://192.168.64.44:5000）。K3s 所需的镜像列表可以从 `K3s Release`页面的`k3s-images.txt`获得。

**1. 配置 K3s 镜像仓库**

启动 K3s 默认会从docker.io拉取镜像。使用containerd容器运行时在离线安装时，我们只需要将镜像仓库地址配置到docker.io下的endpoint即可，更多配置说明请参考配置 containerd 镜像仓库完全攻略或[K3s 官方文档](https://docs.rancher.cn/docs/k3s/installation/private-registry/_index/)：

```bash
sudo mkdir -p /etc/rancher/k3s
sudo cat >> /etc/rancher/k3s/registries.yaml <<EOF
mirrors:
"docker.io":
endpoint:
- "http://192.168.64.44:5000"
- "https://registry-1.docker.io"
EOF
```



**2. 将 K3s 安装脚本和 K3s 二进制文件移动到对应目录并授予可执行权限**

```bash
sudo chmod a+x /root/k3s /root/k3s-install.sh
sudo cp /root/k3s /usr/local/bin/
```



**3. 安装 K3s**

```bash
INSTALL_K3S_SKIP_DOWNLOAD=true /root/k3s-install.sh
```

> 稍等片刻，即可查看到 K3s 已经成功启动：

:::



## Docker + 私有镜像仓库方式

::: details 展开查看详细
假设你已经将同一版本的 K3s 的安装脚本(k3s-install.sh)、K3s 的二进制文件(k3s)下载到了/root目录下。并且 K3s 所需要的镜像已经上传到了镜像仓库（本例的镜像仓库地址为：http://192.168.64.44:5000）。K3s 所需的镜像列表可以从 K3s Release页面的k3s-images.txt获得。

**1. 配置 K3s 镜像仓库**

Docker 不支持像 containerd 那样可以通过修改 docker.io 对应的 endpoint（默认为 https://registry-1.docker.io）来间接修改默认镜像仓库的地址。但在Docker中可以通过配置registry-mirrors来实现从其他镜像仓库中获取K3s镜像。这样配置之后，会先从registry-mirrors配置的地址拉取镜像，如果获取不到才会从默认的docker.io获取镜像，从而满足了我们的需求。

```bash
cat >> /etc/docker/daemon.json <<EOF
{
"registry-mirrors": ["http://192.168.64.44:5000"]
}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker
```



**2、将 K3s 安装脚本和 K3s 二进制文件移动到对应目录并授予可执行权限**

```bash
sudo chmod a+x /root/k3s /root/k3s-install.sh
sudo cp /root/k3s /usr/local/bin/
```



**3. 安装k3s：**

```bash
INSTALL_K3S_SKIP_DOWNLOAD=true INSTALL_K3S_EXEC='--docker' /root/k3s-install.sh
```

:::



### 单结点高可用离线安装

**提供要从 server 节点卸载 K3s，和需要从agent结点卸载K3s，推荐使用高可用安装，关于单结点迁移到高可用状态可参考 [🧷 这篇文章](https://mp.weixin.qq.com/s/Yax2m2uFw2d4lo5sybHsCw)：**

:::: code-group
::: code-group-item 单结点安装

```bash
INSTALL_K3S_SKIP_DOWNLOAD=true ./install.sh
```

然后，要选择添加其他 agent，请在每个 agent 节点上执行以下操作。注意将 `myserver` 替换为 server 的 IP 或有效的 DNS，并将 `mynodetoken` 替换 server 节点的 token，通常在`/var/lib/rancher/k3s/server/node-token`。

```bash
INSTALL_K3S_SKIP_DOWNLOAD=true K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken ./install.sh
```

:::
::: code-group-item 高可用安装

```bash
curl -sfL https://get.k3s.io | sh -s - server \
  --datastore-endpoint='mysql://username:password@tcp(hostname:3306)/database-name'
```

您需要调整安装命令，以便指定`INSTALL_K3S_SKIP_DOWNLOAD=true`并在本地运行安装脚本。您还将利用`INSTALL_K3S_EXEC='args'`为 k3s 提供其他参数。

由于在离线环境中无法使用`curl`命令进行安装，所以您需要参考以下示例，将这条命令行修改为离线安装：

```bash
INSTALL_K3S_SKIP_DOWNLOAD=true INSTALL_K3S_EXEC='server' K3S_DATASTORE_ENDPOINT='mysql://username:password@tcp(hostname:3306)/database-name' ./install.sh
```

:::
::::



## 扩展work节点

K3s 提供了一个安装脚本，可以方便地将其作为服务安装在基于 systemd 或 openrc 的系统上。该脚本可在 [https://get.k3s.io](https://get.k3s.io/) 获得。要使用这种方法安装 K3s，只需运行：

```bash
curl -sfL https://get.k3s.io | sh -
```

运行此安装后：

+ K3s 服务将被配置为在节点重启后或进程崩溃或被杀死时自动重启。
+ 将安装其他实用程序，包括 `kubectl`、`crictl`、`ctr`、`k3s-killall.sh` 和 `k3s-uninstall.sh`。
+ [kubeconfig](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/) 文件将写入到 `/etc/rancher/k3s/k3s.yaml`，由 K3s 安装的 kubectl 将自动使用该文件。

要在 Worker 节点上安装并将它们添加到集群，请使用 `K3S_URL` 和 `K3S_TOKEN` 环境变量运行安装脚本。以下示例演示了如何加入 Worker 节点：

```bash
curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh -
```

设置 `K3S_URL` 参数会使 K3s 以 Worker 模式运行。K3s Agent 将注册到在 URL 上监听的 K3s Server。`K3S_TOKEN` 使用的值存储在 Server 节点上的 `/var/lib/rancher/k3s/server/node-token` 中。

注意：每台主机必须具有唯一的主机名。如果你的计算机没有唯一的主机名，请传递 `K3S_NODE_NAME` 环境变量，并为每个节点提供一个有效且唯一的主机名。



## 嵌入式数据库高可用

> 在 K3s v1.19.1 中，嵌入式 etcd 取代了实验性的 `Dqlite`。这是一个突破性的变化。请注意，不支持从实验性 Dqlite 升级到嵌入式 etcd。如果你尝试升级，升级将不会成功，并且数据将会丢失。

etcd 使用的共识算法是 raft，HA模式下保证三个node开始~

首先，启动一个带有 `cluster-init` 标志的 Server 节点来启用集群和一个令牌，该令牌将作为共享 secret，用于将其他服务器加入集群。

```bash
curl -sfL https://get.k3s.io | K3S_TOKEN=SECRET sh -s - server --cluster-init
```



启动第一台服务器后，使用共享 secret 将第二台和第三台服务器加入集群：

```bash
curl -sfL https://get.k3s.io | K3S_TOKEN=SECRET sh -s - server --server https://<ip or hostname of server1>:6443
```





## 卸载k3s

**卸载k3s：**

::: details 卸载k3s
如果您使用安装脚本安装了 K3s，那么在安装过程中会生成一个卸载 K3s 的脚本。

> 卸载 K3s 会删除集群数据和所有脚本。要使用不同的安装选项重新启动集群，请使用不同的标志重新运行安装脚本。

:::

提供要从 server 节点卸载 K3s，和需要从agent结点卸载K3s：

:::: code-group
::: code-group-item server结点

```bash
/usr/local/bin/k3s-uninstall.sh
```

:::
::: code-group-item agent结点

```bash
/usr/local/bin/k3s-agent-uninstall.sh
```

:::
::::



## 镜像加速

镜像加速配置后，重启服务

```bash
cat > /etc/rancher/k3s/registries.yaml <<EOF
mirrors:
  docker.io:
    endpoint:
      - "https://fogjl973.mirror.aliyuncs.com"
      - "http://hub-mirror.c.163.com"
      - "https://docker.mirrors.ustc.edu.cn"
      - "https://registry.docker-cn.com"
EOF
```

重启k3s使配置生效

```bash
crictl info|grep  -A 5 registry
```

![image-20221031112848849](http://sm.nsddd.top/smimage-20221031112848849.png)





## containerd

+ [https://containerd.io/](https://containerd.io/)

### 架构图

![image-20221110202936935](http://sm.nsddd.top/smimage-20221110202936935.png)

::: details 补充containerd
containerd从docker就开始熟悉的，那么自然从docker开始介绍：

![img](https://sm.nsddd.top/sm952033-20180520115357747-1796034956.png)



> 在docker1.8之前可以使用 `docker -d`。在后面就是 `docker daemon` 。1.11以后：`docker`、`dockerd`。2015年后 OCI 成立，`runtime-spec` 制定
>
> `libcotainer –>  runC`
>
> ```bash
> dockerd = docker engine + containerd + containerd - shim + runC
> ```
>
> …….
>
> 后面 `kubelet` 不支持 `docker` （因为 `docker` 不支持 `CRI`），`kubernetes`使用 `containerd`。`containerd v1.1`后面也支持 `cri` ，

从图中可以看出，docker 对容器的管理和操作基本都是通过 containerd 完成的。 那么，containerd 是什么呢？

> **containerd** 可用作 Linux 和 Windows 的守护进程。它管理其主机系统的整个容器生命周期，从映像传输和存储到容器执行和监督，再到低级存储，再到网络附件等。

**Containerd 是一个工业级标准的容器运行时，它强调简单性、健壮性和可移植性。Containerd 可以在宿主机中管理完整的容器生命周期：容器镜像的传输和存储、容器的执行和管理、存储和网络等。** 详细点说，Containerd 负责干下面这些事情：

+ 管理容器的生命周期(从创建容器到销毁容器)
+ 拉取 / 推送容器镜像
+ 存储管理(管理镜像及容器数据的存储)
+ 调用 `runC` 运行容器(与 `runC` 等容器运行时交互)
+ 管理容器网络接口及网络

⚠️ 注意：**Containerd 被设计成嵌入到一个更大的系统中，而不是直接由开发人员或终端用户使用。**

![image-20221031142456840](http://sm.nsddd.top/smimage-20221031142456840.png)

:::



::: tip 
在上面的安装我们知道了可以选择默认的docker安装。

:::

###  命令

![查看源图像](http://sm.nsddd.top/smcontainerd-docker-k8s-images)





### containerd的配置管理

::: warning 总结
k3s 安装后内置以下 containerd 客户端

+ ctr ： 单纯的容器管理
+ crictl：从 kubernetes 视角触发，对 POD，容器进行管理。

**k3s 内修改 containerd 的配置步骤：**

+ 复制 `/var/lib/rancher/k3s/agent/containerd/config.toml` 为同目录下的新模板
+ 修改 config.toml.tmpl
+ 重启 k3s （systemctl restart k3s) 或者 k3s-agent（systemctl restart k3s-agent）
+ 检查 `/var/lib/rancher/k3s/agent/containerd/config.toml` 

:::



**日志：**

```bash
tail -f /var/lib/rancher/k3s/agent/containerd/containerd.log
```



## 二进制工具

K3s 二进制文件包含许多帮助您管理集群的附加工具。

| 命令                  | 描述                                                         |
| --------------------- | ------------------------------------------------------------ |
| `k3s server`          | 运行 K3s 管理服务器，它还将启动 Kubernetes 控制平面组件，例如 API 服务器、控制器管理器和调度程序。 |
| `k3s agent`           | 运行 K3s 节点代理。这将导致 K3s 作为工作节点运行，启动 Kubernetes 节点服务`kubelet`和`kube-proxy`. |
| `k3s kubectl`         | 运行嵌入式[kubectl](https://kubernetes.io/docs/docs/reference/kubectl/overview/) CLI。如果`KUBECONFIG`未设置环境变量，这将自动尝试使用在`/etc/rancher/k3s/k3s.yaml`启动 K3s 服务器节点时创建的配置文件。 |
| `k3s crictl`          | 运行嵌入式[crictl](https://github.com/kubernetes-sigs/cri-tools/blob/master/docs/crictl.md)。这是一个用于与 Kubernetes 的容器运行时接口 (CRI) 交互的 CLI。对调试很有用。 |
| `k3s ctr`             | 运行嵌入式[ctr](https://github.com/projectatomic/containerd/blob/master/docs/cli.md)。这是 containerd 的 CLI，K3s 使用的容器守护进程。对调试很有用。 |
| `k3s etcd-snapshot`   | 对 K3s 集群数据进行按需备份并上传到 S3。有关详细信息，请参阅[备份和还原](https://docs.k3s.io/backup-restore#backup-and-restore-with-embedded-etcd-datastore-experimental)。 |
| `k3s secrets-encrypt` | 将 K3s 配置为在将机密存储在集群中时对其进行加密。有关详细信息，请参阅[秘密加密](https://docs.k3s.io/security/secrets-encryption)。 |
| `k3s certificate`     | 证书管理                                                     |
| `k3s completion`      | 为 k3s 生成 shell 完成脚本                                   |
| `k3s help`            | 显示命令列表或一个命令的帮助                                 |



## 边缘计算

k3s 非常支持边缘计算，CICD 的部署，可以给我们带来更好的体验。

::: tip 边缘计算是什么？
边缘计算是为应用开发者和服务提供商在网络的边缘侧提供云服务和IT环境服务；目标是在靠近数据输入或用户的地方提供计算、存储和网络带宽。

通俗地说：边缘计算本质上是一种服务，就类似于云计算、大数据服务，但这种服务非常靠近用户；为什么要这么近？目的是为了让用户感觉到刷什么内容都特别快。

:::



**提升了Quick start成功率：**

我们在交付软件的时候，从以前的给一个Java环境到现在需要一个k8s 环境，k3s则集成了，提供开箱即用的交互体验，降低软件的资源占用，并且使运维部署更方便。



## 单节点 SQLite 扩展为 etcd 高可用

> 注意：k3s v1.22.2 及更新版本才支持从单节点 k3s 集群转换为内置 etcd 集群 

















## 安装脚本

::: details k3s 安装脚本
https://get.k3s.io 

Maybe you can try my plan, if you don't choose the domestic route, but you are affected by the firewall. Then you can use `https://ghproxy.com/{github-url}`

:::

::: details 国内镜像加速~
https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh

```
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -
```

:::



## END 链接

<ul><li><div><a href = '13.md' style='float:left'>⬆️上一节🔗  </a><a href = '15.md' style='float: right'>  ️下一节🔗</a></div></li></ul>

+ [Ⓜ️回到目录🏠](../README.md)

+ [**🫵参与贡献💞❤️‍🔥💖**](https://nsddd.top/archives/contributors))

+ ✴️版权声明 &copy; ：本书所有内容遵循[CC-BY-SA 3.0协议（署名-相同方式共享）&copy;](http://zh.wikipedia.org/wiki/Wikipedia:CC-by-sa-3.0协议文本) 

